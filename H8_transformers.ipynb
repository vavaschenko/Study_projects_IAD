{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Трансформеры\n",
    "В этом домашнем задании мы рассмотим использование трансформеров в библиотеке PyTorch. Рассмотрим задачу языкового моделирования. Попробуем генерировать текст нейронной сетью. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ссылка на данные - https://drive.google.com/drive/folders/1x1A4ElliUGBPnHladGMwPxPuGxI8Vnpu?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-20T20:14:12.408695Z",
     "iopub.status.busy": "2021-12-20T20:14:12.407627Z",
     "iopub.status.idle": "2021-12-20T20:14:13.906101Z",
     "shell.execute_reply": "2021-12-20T20:14:13.904958Z",
     "shell.execute_reply.started": "2021-12-20T20:14:12.408554Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем обучать языковую модель для предсказания следущей буквы. Такие языковые модели применяются в распозновании речи, так как предоставляют дополнительную информацию акустической модели при выборе следующего символа. Для начала, откроем файл с данными, посмотрим, какие символы входят в тексты, сколько их. Уберем из текста все символы переноса на новую строку и табуляцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-20T20:14:13.910309Z",
     "iopub.status.busy": "2021-12-20T20:14:13.910050Z",
     "iopub.status.idle": "2021-12-20T20:14:14.897090Z",
     "shell.execute_reply": "2021-12-20T20:14:14.895877Z",
     "shell.execute_reply.started": "2021-12-20T20:14:13.910281Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = '../input/hse-ida-transformers/small_corp_for_test.txt'\n",
    "file = open(path, 'r')\n",
    "data = file.readlines()\n",
    "file.close()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-20T20:14:14.899034Z",
     "iopub.status.busy": "2021-12-20T20:14:14.898750Z",
     "iopub.status.idle": "2021-12-20T20:14:14.907131Z",
     "shell.execute_reply": "2021-12-20T20:14:14.906354Z",
     "shell.execute_reply.started": "2021-12-20T20:14:14.899002Z"
    }
   },
   "outputs": [],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-20T20:14:14.910106Z",
     "iopub.status.busy": "2021-12-20T20:14:14.909280Z",
     "iopub.status.idle": "2021-12-20T20:14:23.931283Z",
     "shell.execute_reply": "2021-12-20T20:14:23.930368Z",
     "shell.execute_reply.started": "2021-12-20T20:14:14.910061Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "newdata = [re.sub(r\"[n\\t\\s]*\",\"\",i) for i in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-20T20:14:23.932937Z",
     "iopub.status.busy": "2021-12-20T20:14:23.932668Z",
     "iopub.status.idle": "2021-12-20T20:14:23.939583Z",
     "shell.execute_reply": "2021-12-20T20:14:23.938711Z",
     "shell.execute_reply.started": "2021-12-20T20:14:23.932907Z"
    }
   },
   "outputs": [],
   "source": [
    "newdata[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обучения модели требуется сначала подготовить текст в подходящий для нейросети вид. Нужно добавить два токена start и end, которые отвечают за начало и конец текста. Используем [ и ] для этой задачи. Также нам нужен токен pad, чтобы заполнять им текст до требуемой длинны для формирования батча.\n",
    "\n",
    "Реализуем метод preprocess класса Preprocessor. Он должен принимать на вход текст и длинну текста, которую мы ожидаем получить на выходе. Текст должен быть переведен в нижний регистр, в конец текста добавляется требуемое число pad токенов, далее текст векторизуется (каждому символу ставится свое число). Вернуть требуется два вектора: полученный результат без последнего токена (на нем будем обучаться) и полученный результат без первого токена (целевые метки при обучении)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-20T20:14:23.940903Z",
     "iopub.status.busy": "2021-12-20T20:14:23.940659Z",
     "iopub.status.idle": "2021-12-20T20:14:24.002267Z",
     "shell.execute_reply": "2021-12-20T20:14:24.001161Z",
     "shell.execute_reply.started": "2021-12-20T20:14:23.940874Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-20T20:14:24.004012Z",
     "iopub.status.busy": "2021-12-20T20:14:24.003408Z",
     "iopub.status.idle": "2021-12-20T20:14:32.882036Z",
     "shell.execute_reply": "2021-12-20T20:14:32.881102Z",
     "shell.execute_reply.started": "2021-12-20T20:14:24.003972Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize \n",
    "import transformers\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-20T20:14:32.884865Z",
     "iopub.status.busy": "2021-12-20T20:14:32.883630Z",
     "iopub.status.idle": "2021-12-20T20:14:32.894934Z",
     "shell.execute_reply": "2021-12-20T20:14:32.894250Z",
     "shell.execute_reply.started": "2021-12-20T20:14:32.884816Z"
    }
   },
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    def __init__(self):\n",
    "        self.alphabet = '_добсркгауфпитнезчм яжлйвцыэь-шхющёъ][ '\n",
    "        self.token2ind = {}\n",
    "        self.ind2token = {}\n",
    "        for i in range(len(self.alphabet)):\n",
    "            self.token2ind[self.alphabet[i]] = i\n",
    "            self.ind2token[i] = self.alphabet[i]\n",
    "        \n",
    "    \n",
    "    def preprocess(self, text, window_size):\n",
    "        if type(text) == list:\n",
    "            text = ''.join(text)\n",
    "        pad = '_'\n",
    "        pad_num = window_size - len(text)\n",
    "        text = text.lower() + pad * (pad_num + 1)\n",
    "        text_num = (list(map(lambda x: self.token2ind[x], text)))\n",
    "        \n",
    "        return (text_num[:-pad_num-3] + text_num[-pad_num-2:]), (text_num[0:1] + text_num[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Текст будет начинаться токеном [ и заканчиваться токеном ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-20T20:14:32.897189Z",
     "iopub.status.busy": "2021-12-20T20:14:32.896195Z",
     "iopub.status.idle": "2021-12-20T20:14:33.208372Z",
     "shell.execute_reply": "2021-12-20T20:14:33.207505Z",
     "shell.execute_reply.started": "2021-12-20T20:14:32.897139Z"
    }
   },
   "outputs": [],
   "source": [
    "newdata = ['['+ x + ']' for x in newdata]\n",
    "newdata[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как мы не располагаем большими мощностями, то ограничим максимальную длину текста. Начнем с 128. \n",
    "Разбиваем тексты на train и test, перемешаем тексты при разбиении, размер тестовой выборки составит 15% от общего числа текстов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-20T20:14:33.212176Z",
     "iopub.status.busy": "2021-12-20T20:14:33.211819Z",
     "iopub.status.idle": "2021-12-20T20:14:33.431131Z",
     "shell.execute_reply": "2021-12-20T20:14:33.429954Z",
     "shell.execute_reply.started": "2021-12-20T20:14:33.212132Z"
    }
   },
   "outputs": [],
   "source": [
    "THRESHOLD = 128\n",
    "\n",
    "justfine = []\n",
    "for x in range(len(newdata)):\n",
    "    if len(newdata[x]) <= THRESHOLD:\n",
    "        justfine.append(newdata[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-20T20:14:33.433090Z",
     "iopub.status.busy": "2021-12-20T20:14:33.432723Z",
     "iopub.status.idle": "2021-12-20T20:14:33.440264Z",
     "shell.execute_reply": "2021-12-20T20:14:33.439292Z",
     "shell.execute_reply.started": "2021-12-20T20:14:33.433025Z"
    }
   },
   "outputs": [],
   "source": [
    "len(justfine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-20T20:14:33.442020Z",
     "iopub.status.busy": "2021-12-20T20:14:33.441790Z",
     "iopub.status.idle": "2021-12-20T20:14:33.544305Z",
     "shell.execute_reply": "2021-12-20T20:14:33.543351Z",
     "shell.execute_reply.started": "2021-12-20T20:14:33.441994Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train, data_test = torch.utils.data.random_split(justfine, [round(len(justfine)*0.85),round(len(justfine)*0.15)],generator=torch.Generator().manual_seed(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем датасет. На вход датасету передается набор текстов, объект класса Preprocessor и размер окна."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-20T20:14:33.546811Z",
     "iopub.status.busy": "2021-12-20T20:14:33.545839Z",
     "iopub.status.idle": "2021-12-20T20:14:33.615778Z",
     "shell.execute_reply": "2021-12-20T20:14:33.614566Z",
     "shell.execute_reply.started": "2021-12-20T20:14:33.546772Z"
    }
   },
   "outputs": [],
   "source": [
    "window_size = 128\n",
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, x, preproc, window_size = 128):\n",
    "        self.x = x\n",
    "        self.preproc = preproc\n",
    "        self.window_size = window_size\n",
    "        pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        prepr = preproc.preprocess(self.x[idx],self.window_size)\n",
    "        return torch.tensor(prepr[0],dtype = torch.int64), torch.tensor(prepr[1],dtype = torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-20T20:14:33.617418Z",
     "iopub.status.busy": "2021-12-20T20:14:33.617197Z",
     "iopub.status.idle": "2021-12-20T20:14:33.629703Z",
     "shell.execute_reply": "2021-12-20T20:14:33.628871Z",
     "shell.execute_reply.started": "2021-12-20T20:14:33.617392Z"
    }
   },
   "outputs": [],
   "source": [
    "preproc = Preprocessor()\n",
    "train_dataset = TextDataset(data_train, preproc=preproc)\n",
    "test_dataset = TextDataset(data_test, preproc=preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-20T20:14:33.631399Z",
     "iopub.status.busy": "2021-12-20T20:14:33.630795Z",
     "iopub.status.idle": "2021-12-20T20:14:33.667941Z",
     "shell.execute_reply": "2021-12-20T20:14:33.667255Z",
     "shell.execute_reply.started": "2021-12-20T20:14:33.631351Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-20T20:14:33.669368Z",
     "iopub.status.busy": "2021-12-20T20:14:33.669034Z",
     "iopub.status.idle": "2021-12-20T20:14:33.677090Z",
     "shell.execute_reply": "2021-12-20T20:14:33.676221Z",
     "shell.execute_reply.started": "2021-12-20T20:14:33.669339Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model=512, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Маскирование используется для того, чтобы \"спрятать\" от модели последующие слова. Так модель будет учиться предсказывать слова последовательно, а не в более крупном контексте. В качестве примера представим предложение \"Дети пишут эссе\", где модели нужно научиться предсказывать \"пишут\" после \"дети\". Если ей не будет известно о том, что после \"пишут\" идет \"эссе\" она в предсказаниях будет опираться только на \"дети\", и такой подход лучше соответствует описанной задаче предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-20T20:14:33.679343Z",
     "iopub.status.busy": "2021-12-20T20:14:33.678593Z",
     "iopub.status.idle": "2021-12-20T20:14:33.692520Z",
     "shell.execute_reply": "2021-12-20T20:14:33.691402Z",
     "shell.execute_reply.started": "2021-12-20T20:14:33.679301Z"
    }
   },
   "outputs": [],
   "source": [
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size:int, d_model:int, nhead:int, d_hid:int, layers:int,dropout:float=0.2):\n",
    "        super(LanguageModel, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size,d_model)\n",
    "        self.pe = PositionalEncoding(d_model,dropout)\n",
    "        self.transformer_encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.transformer_encoder_layer, layers)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model,vocab_size))\n",
    "    \n",
    "    def forward(self, x, src_mask):\n",
    "        x = self.embed(x)\n",
    "        x = self.pe(x)\n",
    "        x = x.transpose(1, 0)\n",
    "        x = self.transformer_encoder(x, src_mask)\n",
    "        x = self.decoder(x)\n",
    "        return x.transpose(1, 0)\n",
    "    \n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        # А вот и то самое маскирование\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-20T20:14:33.695086Z",
     "iopub.status.busy": "2021-12-20T20:14:33.694746Z",
     "iopub.status.idle": "2021-12-20T20:14:33.817754Z",
     "shell.execute_reply": "2021-12-20T20:14:33.816413Z",
     "shell.execute_reply.started": "2021-12-20T20:14:33.695044Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LanguageModel(len('_добсркгауфпитнезчм яжлйвцыэь-шхющёъ][ '),512,8,200,2) #.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем класс для обучения модели и ее валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-20T20:24:36.451118Z",
     "iopub.status.busy": "2021-12-20T20:24:36.450131Z",
     "iopub.status.idle": "2021-12-20T20:24:36.513505Z",
     "shell.execute_reply": "2021-12-20T20:24:36.512166Z",
     "shell.execute_reply.started": "2021-12-20T20:24:36.451074Z"
    }
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "class Trainer:\n",
    "    \n",
    "    def __init__(self, model, train_dataset, test_dataset):\n",
    "        \n",
    "        self.model = model\n",
    "        \n",
    "        self.train_batch_size = 64\n",
    "        self.test_batch_size = 64\n",
    "        \n",
    "        self.train_dataloader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                                            self.train_batch_size,\n",
    "                                                            shuffle = False\n",
    "                                                           )\n",
    "        self.test_dataloader = torch.utils.data.DataLoader(test_dataset, \n",
    "                                                           self.test_batch_size,\n",
    "                                                           shuffle = False\n",
    "                                                           )\n",
    "        self.train_dataloader_size = len(self.train_dataloader)\n",
    "        self.test_dataloader_size = len(self.test_dataloader)\n",
    "        \n",
    "        #self.device = 'cuda:0'\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index=-1) # используем CrossEntrophyLoss, передаем в качетсве параметра \n",
    "                             # ignore index индекс символа _, чтобы модель не штрафовалась за то\n",
    "                             # что идет после закрывающего токена\n",
    "        \n",
    "        self.optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "        \n",
    "        self.steps_to_print = 1000\n",
    "        \n",
    "    def train_one_epoch(self, epoch_number):\n",
    "        step = 0\n",
    "        counted_loss = 0\n",
    "        current_time = time.time()\n",
    "        it = 0\n",
    "        \n",
    "        for batch in self.train_dataloader:\n",
    "            x, y = batch\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            src_mask = model.generate_square_subsequent_mask(window_size).to(device)\n",
    "            \n",
    "            \n",
    "            output = self.model.forward(x,src_mask).logit().transpose(1,2)\n",
    "            loss = self.criterion(output, y)\n",
    "            \n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            step += 1\n",
    "            it += 1\n",
    "            counted_loss += loss.item()\n",
    "            \n",
    "            if step%self.steps_to_print == 0:\n",
    "                result = 'Train epoch '+str(epoch_number)+' | '\n",
    "                result += 'Step '+str(step)+'/'+str(self.train_dataloader_size)+' | '\n",
    "                result += 'Counted loss '+str(counted_loss)+' | '\n",
    "                result += 'ppl '+str(math.exp(counted_loss/it))+' | '\n",
    "                result += 'time '+str(time.time() - current_time) + ' | '\n",
    "                print(result)\n",
    "                current_time = time.time()\n",
    "                counted_loss = 0\n",
    "                it = 0\n",
    "    \n",
    "    def validate_one_epoch(self, epoch_number):\n",
    "        step = 0\n",
    "        counted_loss = 0\n",
    "        current_time = time.time()\n",
    "        it = 0\n",
    "        for batch in self.test_dataloader:\n",
    "            x, y = batch\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            src_mask = generate_square_subsequent_mask(window_size).to(device)\n",
    "            \n",
    "            output = self.model.forward(x,src_mask).logit().transpose(1,2)\n",
    "        \n",
    "            \n",
    "            loss = self.criterion(output, y)\n",
    "            counted_loss += loss.item()\n",
    "            \n",
    "            step += 1\n",
    "            it += 1\n",
    "            if step%(self.steps_to_print//2) == 0:\n",
    "                result = 'Validate epoch '+str(epoch_number)+' | '\n",
    "                result += 'Step '+str(step)+'/'+str(self.test_dataloader_size)+' | '\n",
    "                result += 'Counted loss '+str(counted_loss)+' | '\n",
    "                result += 'ppl '+str(math.exp(counted_loss/it))+' | '\n",
    "                result += 'time '+str(time.time() - current_time) + ' | '\n",
    "                print(result)\n",
    "                current_time = time.time()\n",
    "                counted_loss = 0\n",
    "                it = 0\n",
    "        \n",
    "    def train(self, number_of_epochs):\n",
    "        model.to(device)\n",
    "        for epoch in range(1, number_of_epochs+1):\n",
    "            model.train()\n",
    "            self.train_one_epoch(epoch)\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                self.validate_one_epoch(epoch)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-20T20:24:40.146414Z",
     "iopub.status.busy": "2021-12-20T20:24:40.146112Z"
    }
   },
   "outputs": [],
   "source": [
    "Trainer(model,train_dataset, test_dataset).train(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
